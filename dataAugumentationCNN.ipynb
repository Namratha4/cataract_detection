{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4172,
     "status": "ok",
     "timestamp": 1616393833518,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "0agRU3M0NaMf"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2353,
     "status": "ok",
     "timestamp": 1616393903970,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "AWXTGJvETqTp",
    "outputId": "c74f14fa-2211-44d4-ca22-2278da2d5a65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\namra\\Downloads\\Cataract-Detection-and-Classification-master\\Cataract-Detection-and-Classification-master\\phase 2 Types\\Deep learning\\model_40\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25484,
     "status": "ok",
     "timestamp": 1616394035672,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "3Rn0RQy2PAab",
    "outputId": "278f0686-d5b7-47d8-efb1-447bbaec0a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 410 images belonging to 3 classes.\n",
      "Found 140 images belonging to 3 classes.\n",
      "(32, 128, 128, 1)\n",
      "(32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Training and testing directories\n",
    "train = r'C:\\Users\\namra\\Downloads\\Cataract-Detection-and-Classification-master\\Cataract-Detection-and-Classification-master\\phase 2 Types\\Deep learning\\preprocessed_images_40\\TRAIN_DIR/'\n",
    "test = r'C:\\Users\\namra\\Downloads\\Cataract-Detection-and-Classification-master\\Cataract-Detection-and-Classification-master\\phase 2 Types\\Deep learning\\preprocessed_images_40\\TEST_DIR/'\n",
    "\n",
    "#Augumentation with only zoom and grayscale format\n",
    "\n",
    "train_datagen2 = ImageDataGenerator(horizontal_flip=True, \n",
    "                             vertical_flip = True,\n",
    "                             zoom_range = 0.3,\n",
    "                             rescale=1/255.0\n",
    "                            )\n",
    "\n",
    "#Corresponding generator\n",
    "train_generator2 = train_datagen2.flow_from_directory(\n",
    "    train,\n",
    "    color_mode='grayscale',\n",
    "    target_size = (128,128),\n",
    "    batch_size=32,\n",
    "    class_mode = 'categorical',\n",
    "    seed=42)\n",
    "\n",
    "#ImageDataGenerator for testing/validation data\n",
    "\n",
    "test_datagen2 = ImageDataGenerator(\n",
    "     rescale=1/255.0 )\n",
    "#Using testing data as validation data\n",
    "\n",
    "validation_generator2 = test_datagen2.flow_from_directory(\n",
    "    test,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    target_size = (128,128),\n",
    "    class_mode = 'categorical',\n",
    "    seed=42 )\n",
    "\n",
    "x_train,y_train = next(train_generator2)\n",
    "x_test,y_test = next(validation_generator2)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2093,
     "status": "ok",
     "timestamp": 1616393918417,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "yexILKgTPRdl"
   },
   "outputs": [],
   "source": [
    "#Basic CNN Model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ej7-2E4E4a"
   },
   "source": [
    "Mobile Net **V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1616394457238,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "_gWRvfCV4IwI"
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1616048124740,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "FOBaaFqD4SVK",
    "outputId": "2823e92c-2295-4cd8-9a13-5a10298495d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 410 images belonging to 3 classes.\n",
      "Found 140 images belonging to 3 classes.\n",
      "(32, 128, 128, 3)\n",
      "(32, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "#Training and testing directories\n",
    "# train = 'TRAIN_DIR/'\n",
    "# test = 'TEST_DIR/'\n",
    "train = r'C:\\Users\\namra\\Downloads\\Cataract-Detection-and-Classification-master\\Cataract-Detection-and-Classification-master\\phase 2 Types\\Deep learning\\preprocessed_images_40\\TRAIN_DIR/'\n",
    "test = r'C:\\Users\\namra\\Downloads\\Cataract-Detection-and-Classification-master\\Cataract-Detection-and-Classification-master\\phase 2 Types\\Deep learning\\preprocessed_images_40\\TEST_DIR/'\n",
    "\n",
    "#For RGB images\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True, \n",
    "                             zoom_range = 0.3,\n",
    "                             preprocessing_function = preprocess_input)\n",
    "\n",
    "#Corresponding generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (128,128),\n",
    "    seed=42)\n",
    "\n",
    "#ImageDataGenerator for testing/validation data\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input\n",
    ")\n",
    "#Using testing data as validation data\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (128,128),\n",
    "    seed=42 )\n",
    "\n",
    "x_train,y_train = next(train_generator)\n",
    "x_test,y_test = next(validation_generator)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3424,
     "status": "ok",
     "timestamp": 1616394475405,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "qFXWDY6q5A1P",
    "outputId": "86daede8-d29b-43a5-8145-4a894da6a3de"
   },
   "outputs": [],
   "source": [
    "# mobilenet_weight_path = 'mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n",
    "\n",
    "# mobileNet = MobileNetV2(\n",
    "#     input_shape = (128,128,3),\n",
    "#     alpha=1.0,\n",
    "#     include_top=False,\n",
    "#     weights= mobilenet_weight_path\n",
    "# )\n",
    "\n",
    "# MN_model = Sequential()\n",
    "# MN_model.add(mobileNet)\n",
    "# MN_model.add(layers.GlobalAveragePooling2D())\n",
    "# MN_model.add(layers.Dropout(0.5))\n",
    "# MN_model.add(layers.Dense(3, activation='softmax'))\n",
    "    \n",
    "# MN_model.compile(\n",
    "#         loss='categorical_crossentropy',\n",
    "#         optimizer=Adam(lr=0.00002),\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "\n",
    "# MN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uz6x8lI2nhP"
   },
   "source": [
    "**SQUEEZENET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1327,
     "status": "ok",
     "timestamp": 1616394651497,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "f2UITja42p82",
    "outputId": "c7004e3f-d08b-4667-ca56-c01473b3abb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1616395514228,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "mQCa0yiJ2zc2",
    "outputId": "288cdb4f-31a2-45ce-ecb6-fe337981ea52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 128, 128, 32  896         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 128, 128, 32  128        ['conv2d_20[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 128, 128, 24  792         ['batch_normalization_22[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 128, 128, 24  96         ['conv2d_21[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 128, 128, 24  600         ['batch_normalization_23[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 128, 128, 24  5208        ['batch_normalization_23[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 128, 128, 24  96         ['conv2d_22[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 128, 128, 24  96         ['conv2d_23[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 128, 48  0           ['batch_normalization_24[0][0]', \n",
      "                                )                                 'batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 48)  0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 64, 64, 48)   2352        ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 64, 64, 48)  192         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 64, 64, 48)   2352        ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 64, 64, 48)   20784       ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 64, 64, 48)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 64, 64, 48)  192         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 64, 64, 96)   0           ['batch_normalization_27[0][0]', \n",
      "                                                                  'batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 96)  0           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 32, 32, 64)   6208        ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 32, 32, 64)  256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 32, 32, 64)   4160        ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 32, 32, 64)  256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 32, 32, 64)  256         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 32, 32, 128)  0           ['batch_normalization_30[0][0]', \n",
      "                                                                  'batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 16, 16, 128)  0          ['concatenate_7[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 48)   6192        ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 16, 16, 48)  192         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 16, 16, 48)   2352        ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 16, 16, 48)   20784       ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 16, 16, 48)  192         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 16, 16, 48)  192         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 16, 16, 96)   0           ['batch_normalization_33[0][0]', \n",
      "                                                                  'batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 8, 8, 96)    0           ['concatenate_8[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 8, 8, 24)     2328        ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 8, 8, 24)    96          ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 8, 8, 24)     600         ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 8, 8, 24)     5208        ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 8, 8, 24)    96          ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 8, 8, 24)    96          ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 8, 8, 48)     0           ['batch_normalization_36[0][0]', \n",
      "                                                                  'batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 48)          0           ['concatenate_9[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 3)            147         ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 120,515\n",
      "Trainable params: 119,203\n",
      "Non-trainable params: 1,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bnmomemtum=0.9\n",
    "def fire(x, squeeze, expand):\n",
    "    y  = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation='relu', padding='same')(x)\n",
    "    y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)\n",
    "    y1 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=1, activation='relu', padding='same')(y)\n",
    "    y1 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y1)\n",
    "    y3 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=3, activation='relu', padding='same')(y)\n",
    "    y3 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y3)\n",
    "    return tf.keras.layers.concatenate([y1, y3])\n",
    "\n",
    "def fire_module(squeeze, expand):\n",
    "    return lambda x: fire(x, squeeze, expand)\n",
    "\n",
    "x = tf.keras.layers.Input(shape=[128,128, 3]) # input is 192x192 pixels RGB\n",
    "\n",
    "y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation='relu')(x)\n",
    "y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)\n",
    "y = fire_module(24, 48)(y)\n",
    "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "y = fire_module(48, 96)(y)\n",
    "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "y = fire_module(64, 128)(y)\n",
    "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "y = fire_module(48, 96)(y)\n",
    "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "y = fire_module(24, 48)(y)\n",
    "y = tf.keras.layers.GlobalAveragePooling2D()(y)\n",
    "y = tf.keras.layers.Dense(3, activation='softmax')(y)\n",
    "\n",
    "model = tf.keras.Model(x, y)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss= 'categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1616395447617,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "9QNL7N1zrPAu",
    "outputId": "e606bfbe-abd6-4dfc-ff1c-b699344784b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 3)\n",
      "(32, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = next(train_generator)\n",
    "x_test,y_test = next(validation_generator)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45604,
     "status": "ok",
     "timestamp": 1616395623072,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "IyyXUF_X3tPc",
    "outputId": "8d02107e-c3b6-4c19-84d9-666901299625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.8531 - accuracy: 0.6323 - val_loss: 0.9772 - val_accuracy: 0.4141\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.4633 - accuracy: 0.8995 - val_loss: 0.8697 - val_accuracy: 0.5938\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.3164 - accuracy: 0.9127 - val_loss: 0.4836 - val_accuracy: 0.8516\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.2099 - accuracy: 0.9444 - val_loss: 0.3178 - val_accuracy: 0.8984\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.1523 - accuracy: 0.9788 - val_loss: 0.3233 - val_accuracy: 0.9219\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.1251 - accuracy: 0.9815 - val_loss: 0.3996 - val_accuracy: 0.8750\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.1336 - accuracy: 0.9788 - val_loss: 0.4000 - val_accuracy: 0.8359\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.1256 - accuracy: 0.9762 - val_loss: 0.2472 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0955 - accuracy: 0.9788 - val_loss: 0.3552 - val_accuracy: 0.8672\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0670 - accuracy: 0.9894 - val_loss: 0.2429 - val_accuracy: 0.9219\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0658 - accuracy: 0.9921 - val_loss: 0.2821 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0753 - accuracy: 0.9762 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0842 - accuracy: 0.9868 - val_loss: 0.3837 - val_accuracy: 0.8828\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0743 - accuracy: 0.9788 - val_loss: 0.1868 - val_accuracy: 0.9609\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0563 - accuracy: 0.9921 - val_loss: 0.3447 - val_accuracy: 0.8594\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0513 - accuracy: 0.9947 - val_loss: 0.2089 - val_accuracy: 0.9609\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0416 - accuracy: 0.9947 - val_loss: 0.1987 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0324 - accuracy: 0.9974 - val_loss: 0.2303 - val_accuracy: 0.9297\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.3059 - val_accuracy: 0.9219\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0235 - accuracy: 0.9974 - val_loss: 0.2129 - val_accuracy: 0.9453\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9921Restoring model weights from the end of the best epoch: 14.\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.2614 - val_accuracy: 0.8906\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "#for fitting the model\n",
    "from keras.callbacks import EarlyStopping\n",
    "EPOCHS_SQ = 30\n",
    "\n",
    "STEPS = train_generator.samples//train_generator.batch_size\n",
    "VAL_STEPS = validation_generator.samples//validation_generator.batch_size\n",
    "\n",
    "SQ_STOP = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max',\n",
    "    patience=7,\n",
    "    verbose = 2,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEPS,\n",
    "    epochs=EPOCHS_SQ,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=VAL_STEPS,\n",
    "    callbacks=[SQ_STOP]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1616395962328,
     "user": {
      "displayName": "cataract project",
      "photoUrl": "",
      "userId": "02483468990302267631"
     },
     "user_tz": -330
    },
    "id": "-Fih9YRLtB5m"
   },
   "outputs": [],
   "source": [
    "model.save('spq_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "sd = load_model('spq_model.h5')\n",
    "img_path = r'C:\\Users\\namra\\Downloads\\Cataract-Detection-and-Classification-master\\Cataract-Detection-and-Classification-master\\phase 2 Types\\Deep learning\\preprocessed_images_40\\TEST_DIR\\severe\\severe_165.png'    # dog\n",
    "    #img_path = '/media/data/dogscats/test1/19.jpg'      # cat\n",
    "\n",
    "    # load a single image\n",
    "new_image = load_image(img_path)\n",
    "\n",
    "# check prediction\n",
    "pred = sd.predict(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83219814"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dataAugumentationCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
